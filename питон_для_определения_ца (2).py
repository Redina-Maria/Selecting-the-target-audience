# -*- coding: utf-8 -*-
"""Питон для определения ЦА

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WMYCr3xVgbI4ThEWl-VOamX3J15twcss

Для начала необходимо переименовать вопросы в факторы, которые к ним относятся
"""

import pandas as pd

# Загрузка файла
file = '/content/Книга с данными последними 2352.xlsx'
df = pd.read_excel(file)
# Переименование столбцов
df.rename(columns={'На что Вы обращаете внимание при выборе одежды? Расставьте в порядке приоритетности, где 1 - наиболее приоритетный, 5 - наименее приоритетный. [Качество текстильного изделия]': 'Качество'}, inplace=True)
df.rename(columns={'На что Вы обращаете внимание при выборе одежды? Расставьте в порядке приоритетности, где 1 - наиболее приоритетный, 5 - наименее приоритетный. [Бренд, выпускающий текстильное изделие]': 'Бренд'}, inplace=True)
df.rename(columns={'На что Вы обращаете внимание при выборе одежды? Расставьте в порядке приоритетности, где 1 - наиболее приоритетный, 5 - наименее приоритетный. [Цена изделия]': 'Цена'}, inplace=True)
df.rename(columns={'На что Вы обращаете внимание при выборе одежды? Расставьте в порядке приоритетности, где 1 - наиболее приоритетный, 5 - наименее приоритетный. [Тенденции моды]': 'Мода'}, inplace=True)
df.rename(columns={'На что Вы обращаете внимание при выборе одежды? Расставьте в порядке приоритетности, где 1 - наиболее приоритетный, 5 - наименее приоритетный. [Практичность при использовании]': 'Практичность'}, inplace=True)
df.rename(columns={'Укажите Ваш пол': 'Пол'}, inplace=True)
df.rename(columns={'Укажите Ваш возраст ': 'Возраст'}, inplace=True)

# Сохранение изменений в файл
df.to_excel('Данные_new.xlsx', index=False)

df

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Загрузка данных из файла Excel
df = pd.read_excel('/content/Данные_new.xlsx')

# Подсчет количества мужчин и женщин
male_count = df[df['Пол'] == 'Мужской'].shape[0]
female_count = df[df['Пол'] == 'Женский'].shape[0]

print(f"Количество мужчин: {male_count}")
print(f"Количество женщин: {female_count}")

# Установка темы seaborn
sns.set_theme(style="whitegrid")

# Создание гистограммы для мужчин
plt.figure(figsize=(10, 6))
sns.histplot(data=df[df['Пол'] == 'Мужской'], x='Возраст', kde=True, label='Мужчины', color='blue', bins=39)
plt.title('Распределение мужчин-респондентов по возрасту', fontsize=15)
plt.xlabel('Возраст', fontsize=14)
plt.ylabel('Количество', fontsize=14)
plt.legend(fontsize=12) # Добавление легенды для отображения метки
plt.show()

# Создание гистограммы для женщин
plt.figure(figsize=(10, 6))
sns.histplot(data=df[df['Пол'] == 'Женский'], x='Возраст', kde=True, label='Женщины', color='red', bins=39)
plt.title('Распределение женщин-респондентов по возрасту', fontsize=15)
plt.xlabel('Возраст', fontsize=14)
plt.ylabel('Количество', fontsize=14)
plt.legend(fontsize=12) # Добавление легенды для отображения метки
plt.show()

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Путь к вашему файлу Excel
file_path = '/content/Данные_new.xlsx'

# Чтение данных из Excel
data = pd.read_excel(file_path)

# Кодирование категориальных переменных
le = LabelEncoder()
data['Ощутили ли Вы уход зарубежных брендов одежды?'] = le.fit_transform(data['Ощутили ли Вы уход зарубежных брендов одежды?'])
data['Кем Вы являетесь?'] = le.fit_transform(data['Кем Вы являетесь?'])

# Удаление столбца "Где вы чаще всего совершаете покупки"
data = data.drop(['В каком городе Вы проживаете?', 'Где вы чаще всего совершаете покупки?'], axis=1)

# Замена NaN на среднее значение для числовых столбцов
numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())

# Кластеризация данных
kmeans = KMeans(n_clusters=3, random_state=200)
clusters = kmeans.fit_predict(data.drop('Пол', axis=1))

# Добавление меток кластеров в DataFrame
data['Cluster'] = clusters

# Расчет silhouette score
silhouette = silhouette_score(data.drop('Пол', axis=1), clusters)
print(f"silhouette: {silhouette}")
# Вывод графика
plt.figure(figsize=(10, 6))
plt.scatter(data['Возраст'], data['Каким среднемесячным заработком вы обладаете?'], c=data['Cluster'], cmap='viridis')
plt.xlabel('Возраст')
plt.ylabel('Располагаемый дход в месяц')
plt.title('Кластеризация по возрасту и предпочтению брендов')
plt.colorbar(label='Кластер')
plt.show()

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score
import matplotlib.pyplot as plt

# Путь к вашему файлу Excel
file_path = '/content/Данные для кластеризации 2352.xlsx'

# Чтение данных из Excel
data = pd.read_excel(file_path)

data

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt

# Путь к вашему файлу Excel
file_path = '/content/Данные_new.xlsx'

# Чтение данных из Excel
data = pd.read_excel(file_path)

# Кодирование категориальных переменных
le = LabelEncoder()
data['Ощутили ли Вы уход зарубежных брендов одежды?'] = le.fit_transform(data['Ощутили ли Вы уход зарубежных брендов одежды?'])
data['Кем Вы являетесь?'] = le.fit_transform(data['Кем Вы являетесь?'])

# Удаление столбца "Где вы чаще всего совершаете покупки"
data = data.drop(['В каком городе Вы проживаете?', 'Где вы чаще всего совершаете покупки?'], axis=1)

# Замена NaN на среднее значение для числовых столбцов
numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())

# Кластеризация данных с использованием DBSCAN
dbscan = DBSCAN(eps=0.1, min_samples=1, metric='euclidean') # Настройте eps и min_samples в соответствии с вашими данными
clusters = dbscan.fit_predict(data.drop('Пол', axis=1))

# Добавление меток кластеров в DataFrame
data['Cluster'] = clusters

# Расчет silhouette score (может быть не совсем подходящим для DBSCAN)
silhouette = silhouette_score(data.drop('Пол', axis=1), clusters)
print(f"silhouette: {silhouette}")

# Вывод графика
plt.figure(figsize=(10, 6))
plt.scatter(data['Возраст'], data['Каким среднемесячным заработком вы обладаете?'], c=data['Cluster'], cmap='viridis')
plt.xlabel('Возраст')
plt.ylabel('Располагаемый доход в месяц')
plt.title('Кластеризация по возрасту и предпочтению брендов с использованием DBSCAN')
plt.colorbar(label='Кластер')
plt.show()

"""ВЫШЕ НЕ ТРОГАТЬ!"""

# Нормализация числовых столбцов
numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns
scaler = StandardScaler()
data[numeric_cols] = scaler.fit_transform(data[numeric_cols])

# Оптимизация гиперпараметров DBSCAN с помощью перекрестной проверки
from sklearn.model_selection import GridSearchCV

params = {'eps': [0.3, 0.4, 0.5], 'min_samples': [1, 2, 3]}
grid_search = GridSearchCV(DBSCAN(), params, cv=5, scoring='silhouette')
#grid_search.fit(data.drop('Пол', axis=1))

# Получение оптимальных гиперпараметров
best_params = grid_search.best_params_
eps = best_params['eps']
min_samples = best_params['min_samples']

# Создание модели DBSCAN с оптимальными гиперпараметрами
dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')
clusters = dbscan.fit_predict(data.drop('Пол', axis=1))

from sklearn.metrics import davies_bouldin_score

# Расчет коэффициента Данна
dunn_score = dunn(data.drop('Пол', axis=1), clusters)

# Расчет индекса Дэвиса-Булдина
db_score = davies_bouldin_score(data.drop('Пол', axis=1), clusters)

# Визуализация кластеров с помощью параллельных координат
from pandas.plotting import parallel_coordinates

parallel_coordinates(data.drop('Пол', axis=1), color=[data['Cluster']])
plt.show()

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.cluster import DBSCAN
from sklearn.metrics import silhouette_score, davies_bouldin_score
import matplotlib.pyplot as plt

# Путь к вашему файлу Excel
file_path = '/content/Данные_new.xlsx'

# Чтение данных из Excel
data = pd.read_excel(file_path)

# Кодирование категориальных переменных
le = LabelEncoder()
data['Ощутили ли Вы уход зарубежных брендов одежды?'] = le.fit_transform(data['Ощутили ли Вы уход зарубежных брендов одежды?'])
data['Кем Вы являетесь?'] = le.fit_transform(data['Кем Вы являетесь?'])

# Удаление столбца "Где вы чаще всего совершаете покупки"
data = data.drop(['В каком городе Вы проживаете?', 'Где вы чаще всего совершаете покупки?'], axis=1)

# Замена NaN на среднее значение для числовых столбцов
numeric_cols = data.select_dtypes(include=['int64', 'float64']).columns
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())

# Кластеризация данных с использованием DBSCAN
dbscan = DBSCAN(eps=0.2, min_samples=3, metric='euclidean') # Настройте eps и min_samples в соответствии с вашими данными
clusters = dbscan.fit_predict(data.drop('Пол', axis=1))

# Добавление меток кластеров в DataFrame
data['Cluster'] = clusters

# Расчет silhouette score и davies-bouldin score
silhouette = silhouette_score(data.drop('Пол', axis=1), clusters)
db_score = davies_bouldin_score(data.drop('Пол', axis=1), clusters)
print(f"Silhouette Score: {silhouette}")
print(f"Davies-Bouldin Score: {db_score}")

# Вывод графика
plt.figure(figsize=(10, 6))
plt.scatter(data['Возраст'], data['Каким среднемесячным заработком вы обладаете?'], c=data['Cluster'], cmap='viridis')
plt.xlabel('Возраст')
plt.ylabel('Располагаемый доход в месяц')
plt.title('Кластеризация по возрасту и предпочтению брендов с использованием DBSCAN')
plt.colorbar(label='Кластер')
plt.show()